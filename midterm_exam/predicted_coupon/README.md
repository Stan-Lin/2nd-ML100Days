# ML100 Midterm Exam

https://www.kaggle.com/c/ml100marathon-02-01/leaderboard

First, I don't explore data deeply because it's easy to follow the others methods.

The releated and important data are picked to model that don't take much unstble factors.

Second, I focus to the parameter tunning in model which is created by stacking mechanism with SGD,Random Forest and XGBoost.

## Finally, I got the second place in LB (284 teams). 

![image](https://i.imgur.com/ldaBAeG.png)
